package ca.ilanguage.aublog.ui;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.Locale;

import com.google.android.apps.analytics.GoogleAnalyticsTracker;

import android.app.Activity;
import android.content.ContentValues;
import android.content.Context;
import android.content.Intent;
import android.content.SharedPreferences;
import android.content.res.Configuration;
import android.database.ContentObserver;
import android.database.Cursor;
import android.database.SQLException;
import android.media.AudioManager;
import android.media.MediaPlayer;
import android.media.MediaRecorder;
import android.net.Uri;
import android.os.Build;
import android.os.Bundle;
import android.os.Handler;
import android.speech.tts.TextToSpeech;
import android.util.Log;
import android.view.KeyEvent;
import android.view.Menu;
import android.view.MenuInflater;
import android.view.MenuItem;
import android.webkit.WebSettings;
import android.webkit.WebView;
import android.widget.Toast;

import ca.ilanguage.aublog.R;
import ca.ilanguage.aublog.db.AuBlogHistoryDatabase;
import ca.ilanguage.aublog.db.AuBlogHistoryDatabase.AuBlogHistory;
import ca.ilanguage.aublog.preferences.NonPublicConstants;
import ca.ilanguage.aublog.preferences.PreferenceConstants;
import ca.ilanguage.aublog.preferences.SetPreferencesActivity;
import ca.ilanguage.aublog.service.DictationRecorderService;
import ca.ilanguage.aublog.service.NotifyingTranscriptionIntentService;
import ca.ilanguage.aublog.service.NotifyingTranscriptionService;

/**
 * Demonstrates how to embed a WebView in your activity. Also demonstrates how
 * to have javascript in the WebView call into the activity, and how the activity 
 * can invoke javascript.
 * <p>
 * In this example, clicking on the android in the WebView will result in a call into
 * the activities code in {@link DemoJavaScriptInterface#clickOnAndroid()}. This code
 * will turn around and invoke javascript using the {@link WebView#loadUrl(String)}
 * method.
 * <p>
 * Obviously all of this could have been accomplished without calling into the activity
 * and then back into javascript, but this code is intended to show how to set up the 
 * code paths for this sort of communication.
 *
 */
public class EditBlogEntryActivity extends Activity implements TextToSpeech.OnInitListener {

	GoogleAnalyticsTracker tracker;
	private String mAuBlogInstallId;
    private static final String TAG = "CreateBlogEntryActivity";
    /** Talk to the user */
    private TextToSpeech mTts;
    private Menu mMenu;
    private String mBloggerAccount;
	private String mBloggerPassword;
    private Long mTimeAudioWasRecorded;
    private String mAudioSource;//bluetooth(record,play), phone(recordmic, play earpiece) for privacy, speaker(record mic, play speaker)
    private Boolean mUseBluetooth;
    private Boolean mUsePhoneEarPiece;
    
    private String mAuBlogDirectory = PreferenceConstants.OUTPUT_AUBLOG_DIRECTORY;//"/sdcard/AuBlog/";
    private AudioManager mAudioManager;
    
    private MediaPlayer mMediaPlayer;
    Boolean mRecordingNow;
    Boolean mPlayingNow;
    private Boolean mReadBlog;
    private Boolean mSendForTranscription = false;
    //DONE adde recording logic 
    //DONE figure out the problems with the account database,decoup0le the account database with the blog entry screen
    
	//uri of the entry being edited.
	private Uri mUri;
	private Cursor mCursor;
	public AuBlogHistoryContentObserver mAuBlogContentObserver;
	
	int selectionStart;
	int selectionEnd;
	//DONE removed member varibles which are only changed in javascript title, content and labels
	String mPostParent ="";
	String mPostId ="";
	String mAudioResultsFile;
	String mAudioResultsFileStatus;
	//Boolean mFreshEditScreen;
	private Boolean mDeleted = false;
	String mLongestEverContent ="";
	private  String[] PROJECTION = new String[] {
		AuBlogHistory._ID, //0
		AuBlogHistory.ENTRY_TITLE, 
		AuBlogHistory.ENTRY_CONTENT, //2
		AuBlogHistory.ENTRY_LABELS,
		AuBlogHistory.PUBLISHED, //4
		AuBlogHistory.DELETED,
		AuBlogHistory.PARENT_ENTRY, //6
		AuBlogHistory.PUBLISHED_IN,
		AuBlogHistory.TIME_CREATED,//8
		AuBlogHistory.LAST_MODIFIED,  //this is a value generated by a database save LAST_EDITED is a value generated by the EditBlogEntryActivity
		AuBlogHistory.AUDIO_FILE,//10
		AuBlogHistory.AUDIO_FILE_STATUS
	};
	
	
	private WebView mWebView;
	
	private class AuBlogHistoryContentObserver extends ContentObserver {

		public AuBlogHistoryContentObserver(){
			super(null);
		}
		
		@Override
		public void onChange(boolean selfChange) {
			
			super.onChange(selfChange);
			getAudioFileDataOutOfDatabase();
		}
		
	}
    
    //implement on Init for the text to speech
	public void onInit(int status) {
		if (status == TextToSpeech.SUCCESS) {
			// Set preferred language to US english.
			// Note that a language may not be available, and the result will
			// indicate this.
			int result = mTts.setLanguage(Locale.US);
			// Try this someday for some interesting results.
			// int result mTts.setLanguage(Locale.FRANCE);
			if (result == TextToSpeech.LANG_MISSING_DATA
					|| result == TextToSpeech.LANG_NOT_SUPPORTED) {
				// Language data is missing or the language is not supported.
				Log.e(TAG, "Language is not available.");
				//Toast.makeText(EditBlogEntryActivity.this, "The English TextToSpeech isn't installed, you can go into the \nAndroid's settings in the \nVoice Input and Output menu to turn it on. ", Toast.LENGTH_LONG).show();

			} else {
				//everything is working.
			}
		} else {
			// Initialization failed.
			tracker.trackEvent(
		            "DependantPackages",  // Category
		            "FileManager",  // Action
		            "user doesnt have TTS, in the init failed section, didnt take them to package manager: "+mAuBlogInstallId, // Label
		            301);       // Value
        	
			Log.e(TAG, "Sorry, I can't talk to you because I could not initialize TextToSpeech.");
		}
	}
	/**
	 * Important Potential Hazard of Bluetooth and changing Audio Settings in the middle of an activity:
	 * 
	 * Using the bluetooth for audio in 2.2 has a bug which has been documented here:
	 * http://code.google.com/p/android/issues/detail?id=9503
	 * Bottom line: this activity can crash the phone if the user turns off the bluetooth device in this activity, in Android 2.2.  
	 * 
	 * 
	 * - Steps to reproduce the problem (including sample code if appropriate).
		
		using startBluetoothSco/stopBluetoothSco on Android 2.2 (FRF85B)
		don't exit the app that called them
		then disable or disconnect link to bluetooth headset
		
		- What happened.
		
		The system rebooted because of a crash in AudioService.java. When the headset gets disconnected it tries to call unlinkToDeath with "noSuchElementExceptions: death link does not exist"
		
		- What you think the correct behavior should be.
		
		When calling stopBluetoothSco the ScoClient should get removed from the list of ScoClients.
		
		
	 */
	private void recheckAublogSettings(){
    	SharedPreferences prefs = getSharedPreferences(PreferenceConstants.PREFERENCE_NAME, MODE_PRIVATE);
		/*
		 * set the installid for appending to the labels
		 */
		mAuBlogInstallId = prefs.getString(PreferenceConstants.AUBLOG_INSTALL_ID, "0");

		mReadBlog = prefs.getBoolean(PreferenceConstants.PREFERENCE_SOUND_ENABLED, true);
	    mUseBluetooth = prefs.getBoolean(PreferenceConstants.PREFERENCE_USE_BLUETOOTH_AUDIO, false);
	    mUsePhoneEarPiece = prefs.getBoolean(PreferenceConstants.PREFERENCE_USE_PHONE_EARPIECE_AUDIO, false);
	   
	    if(mUseBluetooth){
			/*
	    	 * As the SCO connection establishment can take several seconds, applications should not rely on the connection to be available when the method returns but instead register to receive the intent ACTION_SCO_AUDIO_STATE_CHANGED and wait for the state to be SCO_AUDIO_STATE_CONNECTED.
	    	 Even if a SCO connection is established, the following restrictions apply on audio output streams so that they can be routed to SCO headset: - the stream type must be STREAM_VOICE_CALL - the format must be mono - the sampling must be 16kHz or 8kHz

				Similarly, if a call is received or sent while an application is using the SCO connection, the connection will be lost for the application and NOT returned automatically when the call ends.
			* Notes:
			* Use of the blue tooth does not affect the ability to recieve a call while using the app,
			* However, the app will not have control of hte bluetooth connection when teh phone call comes back. The user must exit the Edit Blog activity.
			* 
	    	 */
	    	mAudioManager.startBluetoothSco();
	    	mAudioManager.setSpeakerphoneOn(false);
	    	mAudioManager.setBluetoothScoOn(true);
	    	
	    	setVolumeControlStream(AudioManager.STREAM_VOICE_CALL);
	    	mAudioManager.setMode(AudioManager.MODE_IN_CALL);
		    mAudioSource= "maybebluetooth";
		}
		if(mUsePhoneEarPiece){
			/*
	    	 * This works.
	    	 * 
	    	 * This constant ROUTE_EARPIECE is deprecated. Do not set audio routing directly, use setSpeakerphoneOn(), setBluetoothScoOn() methods instead.
	    	 */
	    	mAudioManager.setSpeakerphoneOn(false);
	    	//routes to earpiece by default when speaker phone is off. 
	    	//mAudioManager.setRouting(AudioManager.MODE_NORMAL, AudioManager.ROUTE_EARPIECE, AudioManager.ROUTE_ALL); 
	    	setVolumeControlStream(AudioManager.STREAM_VOICE_CALL);
	    	mAudioManager.setMode(AudioManager.MODE_IN_CALL);
	    	mAudioSource= "microphone";

		}
    	/*
    	 * then the app can use the media player as usual
    	 */
    }
    
    @Override
	protected void onStart() {
    	recheckAublogSettings();
	    /**
         * Get the uri which was sent to the CreateBlogActivity, put the data into the fields.
         */
    	String fillFromActivityValues="";
        mUri = getIntent().getData();
        mCursor = managedQuery(mUri, PROJECTION, null, null, null);
        if (mCursor != null) {
			// Requery in case something changed while paused (such as the title)
			mCursor.requery();
            // Make sure we are at the one and only row in the cursor.
            mCursor.moveToFirst();
			try {
					fillFromActivityValues=mCursor.getString(1)+":::--:::"+ mCursor.getString(2)+":::--:::"+mCursor.getString(3);
					mPostId = mCursor.getString(0);
					mPostParent = mCursor.getString(6);
					getAudioFileDataOutOfDatabase();
					if("0".equals(mCursor.getString(5))){ 
						mDeleted=false;
					}else{
						mDeleted=true;
					}

			} catch (IllegalArgumentException e) {
				// Log.e(TAG, "IllegalArgumentException (DataBase failed)");
				tracker.trackEvent(
			            "Database",  // Category
			            "Bug",  // Action
			            "Retrieval from DB failed with an illegal argument exception "+e+" : "+mAuBlogInstallId, // Label
			            301);       // Value
				Toast.makeText(EditBlogEntryActivity.this, "Retrieval from DB failed with an illegal argument exception "+e, Toast.LENGTH_LONG).show();
			} catch (Exception e) {
				// Log.e(TAG, "Exception (DataBase failed)");
				tracker.trackEvent(
			            "Database",  // Category
			            "Bug",  // Action
			            "The cursor returned is "+e+" : "+mAuBlogInstallId, // Label
			            302);       // Value
				//Toast.makeText(EditBlogEntryActivity.this, "The cursor returned is "+e, Toast.LENGTH_LONG).show();
			}
        }else{
			//this should never be executed
		}
		mWebView.loadUrl("file:///android_asset/edit_blog_entry_wysiwyg.html");
		mWebView.loadUrl("javascript:fillTitleContentLabels("+fillFromActivityValues+")");
    	super.onStart();
	}
    
    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        mTts = new TextToSpeech(this, this);
        mAudioManager = (AudioManager)getSystemService(Context.AUDIO_SERVICE);
        mMediaPlayer = new MediaPlayer();
        mMediaPlayer.setLooping(true);
        mRecordingNow = false;
        tracker = GoogleAnalyticsTracker.getInstance();
	    // Start the tracker in manual dispatch mode...
	    tracker.start(NonPublicConstants.NONPUBLIC_GOOGLE_ANALYTICS_UA_ACCOUNT_CODE, 20, this);

        mAuBlogContentObserver = new AuBlogHistoryContentObserver();
        this.getApplicationContext().getContentResolver().registerContentObserver(AuBlogHistory.CONTENT_URI, true, mAuBlogContentObserver);
           
        setContentView(R.layout.main_webview);
        mWebView = (WebView) findViewById(R.id.webview);
        mWebView.addJavascriptInterface(new JavaScriptInterface(this), "Android");
        WebSettings webSettings = mWebView.getSettings();
        webSettings.setSavePassword(false);
        webSettings.setSaveFormData(true);
        webSettings.setJavaScriptEnabled(true);
        		
    }
    public class JavaScriptInterface {
        Context mContext;

        /** Instantiate the interface and set the context */
        JavaScriptInterface(Context c) {
            mContext = c;
        }
        public void showToast(String toast) {
            Toast.makeText(mContext, toast, Toast.LENGTH_SHORT).show();
        }
        public void readToTTS(String message){
        	recheckAublogSettings(); //if user turned off tts dont read it
        	if(mReadBlog){
        		readTTS(message);
        	}else{
        		tracker.trackEvent(
        	            "TTS",  // Category
        	            "notUsed",  // Action
        	            "there was a message that was not read via TTS because it is off in the settings: "+message+" : "+mAuBlogInstallId, // Label
        	            362);       // Value
        	}
        }
        /*
         * methods to record and manage recording of blog entry
         * TODO add some infomesages into the tool bar
         */
        public String startToRecord(String postTitle){
        	return beginRecording(postTitle);
        }
        public String stopRecord(){
        	return stopSaveRecording();
        }
        
        public String playOrPauseAudio(){
        	return playOrPauseAudioFile();
        }
        public Long getTimeRecorded(){
        	return returnTimeRecorded();
        }
        public String fetchTitleContentLabels(String concatenated){
        	return concatenated;
        }
        public String fetchDebugInfo(){
        	return "Id: "+mPostId+" Parent: "+mPostParent+" Deleted: "+mDeleted.toString()+" LongestEverString:"+mLongestEverContent;
        }
        public void savePostToDB(String strTitle, String strContent, String strLabels){
        	tracker.trackEvent(
    	            "AuBlogLifeCycleEvent",  // Category
    	            "saveSTate",  // Action
    	            "Javascript was saved to database "+strTitle+" : "+strLabels+" : "+strContent+" : "+mAuBlogInstallId, // Label
    	            34);       // Value
        	saveAsSelfToDB(strTitle, strContent, strLabels);
        }
        public void savePostAsDaughter(String strTitle, String strContent, String strLabels){
//        	mPostContent= strContent;
//        	mPostTitle=strTitle;
//        	mPostLabels=strLabels;
//        	saveState(strTitle, strContent, strLabels);//dont save the post to this entry, instead it should only go in the next entry.
        	saveAsDaughterToDB(strTitle, strContent, strLabels);
    		//Toast.makeText(EditBlogEntryActivity.this, "Saved \n\""+mPostTitle+"\"", Toast.LENGTH_LONG).show();

        }
        public void deletePost(String strTitle, String strContent, String strLabels){
//        	saveState(strTitle, strContent, strLabels);
        	deleteEntry(mUri);
        	finish();
        }
        public void publishPost(String strTitle, String strContent, String strLabels){
        	//act like publish is both save+publish
        	saveAsDaughterToDB(strTitle, strContent, strLabels);
        	if ((strTitle.length() == 0)
        			|| (strTitle == null)
        			|| (strContent.length() == 0)
        			|| (strContent == null)) {
        		tracker.trackEvent(
			            "Publish",  // Category
			            "Error",  // Action
			            "displayed Toast:"+R.string.title_or_content_empty_error+" : "+mAuBlogInstallId, // Label
			            30);       // Value
        		Toast.makeText(EditBlogEntryActivity.this, R.string.title_or_content_empty_error, Toast.LENGTH_LONG).show();
        	} else {
        		SharedPreferences prefs = getSharedPreferences(PreferenceConstants.PREFERENCE_NAME, MODE_PRIVATE);
    		    mBloggerAccount = prefs.getString(PreferenceConstants.PREFERENCE_ACCOUNT, "see settings");
        		mBloggerPassword = prefs.getString(PreferenceConstants.PREFERENCE_PASSWORD, "see settings");
        		if( (!mBloggerAccount.contains("@") ) || mBloggerPassword.length()<4 ){
        			tracker.trackEvent(
    			            "Publish",  // Category
    			            "Error",  // Action
    			            "displayed Toast: Taking you to the settings to add a Blogger account.: "+mAuBlogInstallId, // Label
    			            302);       // Value
        			Toast.makeText(EditBlogEntryActivity.this, "No Blogger account found.\n\nTaking you to the settings to \n\nConfigure a Blogger account.", Toast.LENGTH_LONG).show();
        			Intent i = new Intent(EditBlogEntryActivity.this, SetPreferencesActivity.class);
            		startActivity(i);
        		}else{
        		
	        		tracker.setCustomVar(1, "Navigation Type", "Button click", 22);
	    			tracker.trackPageView("/publishBlogEntryScreen");
	    			
	        		Intent i = new Intent(EditBlogEntryActivity.this, PublishActivity.class);
	        		//tell the i the mUri that is supposed to be published
	        		i.setData(mUri);
	        		startActivity(i);
	        		finish();
        		}
        	}
        }
    }
   



	@Override
	protected void onPause() {
		/*
		 * Un-user-initiated saves do not create a new node in the draft tree
		 * (although, this can be changed by just calling saveAsDaugher here) 1.
		 * asks Javascript to put current values into state 2. saves state to
		 * database as self
		 * 
		 * Potential bug: this needs to operate syncronously, if operated async,
		 * then the changed values in the javascript will never be perserved
		 * unless the user hits save first (before hitting back button or
		 * rotating screen).
		 * 
		 * Rotate screen: save as self to database Back button: save as self to
		 * database
		 */
		mWebView.loadUrl("javascript:savePostToTheDB()");
		tracker.trackEvent("Event", // Category
				"Pause", // Action
				"event was paused: " + mAuBlogInstallId, // Label
				38); // Value

		// http://developer.android.com/guide/topics/media/index.html
		/*
		 * As you may know, when the user changes the screen orientation (or
		 * changes the device configuration in another way), the system handles
		 * that by restarting the activity (by default), so you might quickly
		 * consume all of the system resources as the user rotates the device
		 * back and forth between portrait and landscape, because at each
		 * orientation change, you create a new MediaPlayer that you never
		 * release.
		 * 
		 * DONE: playing and pausing is kept in the EditBlog activity, if the
		 * user rotatest the screen or leaves it will stop playing. This is
		 * preferred. If the user wants to listen to their audio in the
		 * background they can use the normal Music player by opening the
		 * settings, and going to the audio folder.
		 * 
		 * DONE: refactored record as a service (foregrounded so that it will be
		 * less likely to be killed by android) Aublog will record a dictation
		 * until A: the user clicks stop in the EditBlogEntryActivity B: the
		 * users quits Aublog MainMenuActivity (ondestroy method) C: the user
		 * clicks on the notification, goes to the NotificationController and
		 * clicks Stop Recording. D: the system runs out of memory E: the
		 * service is killed by the system F: (aublog is killed by the system?)
		 * the service should be running in the same process id, so technically
		 * the service's ondestroy will be killed of aublog is killed.
		 * 
		 * Consequences: NEGATIVE: to find out if the audio file is valid, or
		 * how long it is, this EditBlogEntry now has to go to the database and
		 * the Sdcard, it cant know on its own. POSITIVE: the user can rotate
		 * the screen while dictating, which is very natural since they will
		 * pick up and put down the phone, walk around, maybe biking etc
		 * especially if the user is using a bluetooth.
		 */

		super.onPause();
	}

	@Override
	protected void onDestroy() {
		tracker.stop();
		/*
		 * If the mediaplayer exists or is playing, release it,
		 */
		if (mMediaPlayer != null) {
			mMediaPlayer.release();
			mMediaPlayer = null;
		}
		super.onDestroy();
	}
	
	public void deleteEntry(Uri uri){
    	mDeleted = true;
    	/*
		 * Flag entry as deleted
		 */
    	tracker.trackEvent(
	            "AuBlogLifeCycleEvent",  // Category
	            "Delete",  // Action
	            "entry was flagged as deleted in the database"+uri.getLastPathSegment()+" : "+mAuBlogInstallId, // Label
	            39);       // Value
		ContentValues values = new ContentValues();
		values.put(AuBlogHistory.DELETED,"1");//sets deleted flag to true
		getContentResolver().update(uri, values,null, null);
//		getContentResolver().delete(uri, null, null);
		flagDraftTreeAsNeedingToBeReGenerated();
		Toast.makeText(EditBlogEntryActivity.this, "Post " +uri.getLastPathSegment()+" deleted.", Toast.LENGTH_LONG).show();
		finish();
	}
	/*
	 * An android method to wrap a call to the TTS engine, the logic of if the app should use text to speech (based on settings check box) is handled in the javascript interface. 
	 */
	public void readTTS(String message){
		tracker.trackEvent(
	            "TTS",  // Category
	            "Use",  // Action
	            "spoke message: "+message+" : "+mAuBlogInstallId, // Label
	            361);       // Value
		mTts.speak(message,TextToSpeech.QUEUE_ADD, null);
		
	}
	public Boolean hasAudioFileAttached(){
		if (mAudioResultsFile.length() > 5 ){
			//Toast.makeText(EditBlogEntryActivity.this,"There is an audio file.", Toast.LENGTH_SHORT).show();
    		return true;
    	}else{
			//Toast.makeText(EditBlogEntryActivity.this,"No audio file.", Toast.LENGTH_SHORT).show();
    		return false;
    	}
	}
	/**
	 * Launches a service to record 
	 * 
	 * @return
	 */
	public String beginRecording(String postTitle){
		mAudioResultsFileStatus = "recording service started";
		String dateString = (String) android.text.format.DateFormat.format("yyyy-MM-dd_hh.mm", new java.util.Date());
		dateString = dateString.replaceAll("/","-");
		mAudioResultsFile = mAuBlogDirectory+"audio/";
		new File(mAudioResultsFile).mkdirs();
		mAudioResultsFile=mAudioResultsFile+mAuBlogInstallId+"_"+dateString+"_"+System.currentTimeMillis()+"_"+postTitle+".mp3"; 
		mAudioResultsFile=mAudioResultsFile.replaceAll(" ","-");
		mRecordingNow = true;
		Intent intent = new Intent(this, DictationRecorderService.class);
	 	intent.setData(mUri);
	 	intent.putExtra(DictationRecorderService.EXTRA_AUDIOFILE_FULL_PATH, mAudioResultsFile);
	    intent.putExtra(DictationRecorderService.EXTRA_AUDIOFILE_STATUS, mAudioResultsFileStatus);
	    startService(intent);
		return "Recording...";
	}
	/**
	 * A function which starts or pauses the media player.
	 * The media player is run in a loop so the user only has two options (Play,Pause) not three (Play,Pause,Stop)
	 * This design choice was made so that the user can transcribe their dictation. If they would like to listen to the audio they can 
	 * open the AuBlog settings to go to the AuBlog folder (its easy to find, its in the root of the SDCard) and play their dictations using the music player.
	 * Users can also use the Music player to make a play list of their dictations if they would like to listen continously to their dictations rather than transcribe them.
	 * 
	 * @return A message for the button which is the oposite of its current state. (ie, if the player is paused, it returns Play, if the player is started, it returns Pause)
	 */
	public String playOrPauseAudioFile(){
		if(mMediaPlayer.isPlaying()){
			mMediaPlayer.pause();
			/* TODO rewind logic doesnt work
			 * //if its playing, pause and rewind ~4 seconds
			int rewindValue = 2;
			int startPlayingFromSecond =mMediaPlayer.getCurrentPosition();
			if ( startPlayingFromSecond <= rewindValue){
				startPlayingFromSecond=0;
			}else{
				startPlayingFromSecond = startPlayingFromSecond - rewindValue;
			}
			mMediaPlayer.seekTo(startPlayingFromSecond);
			mMediaPlayer.prepareAsync();
			*/
			return "Play";
		}else{
			//if its not playing, play it
		    try {
		    	mMediaPlayer.start();
			} catch (IllegalArgumentException e) {
				// TODO Auto-generated catch block
				Log.e("Error reading file", e.toString());
			} catch (IllegalStateException e) {
				// TODO Auto-generated catch block
				Log.e("Error reading file", e.toString());
			} 
			return "Pause";
		}
		
	}
	/**
	 * This method gets audio file information out of the database, if the information contains a valid 
	 * audiofilename, it will set up the play button and the media player. 
	 */
	private void getAudioFileDataOutOfDatabase(){
		/*
	   	 * get data from database.
	   	 */
		// Requery in case something changed while paused (such as the title)
		mCursor.requery();
        // Make sure we are at the one and only row in the cursor.
        mCursor.moveToFirst();
		try {
			mAudioResultsFile = mCursor.getString(10);
			mAudioResultsFileStatus = mCursor.getString(11);
    		/*
    		 * Extract the time of the audio that was recorded.
    		 */
    		mTimeAudioWasRecorded =extractTimeRecordedFromAudioFileStatus(mAudioResultsFileStatus);
    		
		} catch (IllegalArgumentException e) {
			tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Database connection IllegalArgumentException in extractingn audiofile info after stopping recording"+e+" : "+mAuBlogInstallId, // Label
    	            3101);       // Value
		} catch (Exception e) {
			tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Database connection Exception in extracting audiofile info after stopping recording"+e+" : "+mAuBlogInstallId, // Label
    	            3101);       // Value
		}
		/*
	   	 * assign this audio recording to the media player
	   	 */
	   	try {
	   		/*
	   		 * bug: was not changing the data source here, so decided to reset the audio player completely and
	   		 * reinitialize it
	   		 */
	   		if (mAudioResultsFile.length() > 5){
	   			if(mMediaPlayer != null){
	   				mMediaPlayer.release();
	   				mMediaPlayer = null;
	   			}
		   		
		   		//TODO put this back in after done debuging refactoring recheckAublogSettings();//if audio settings have changed use the new ones.
		   		mWebView.loadUrl("javascript:displayPlayButton()");
		   		mMediaPlayer = new MediaPlayer();
		        mMediaPlayer.setLooping(true);
		   		mMediaPlayer.setDataSource(mAudioResultsFile);
				mMediaPlayer.prepareAsync();
	   		}
		} catch (IllegalArgumentException e) {
			// TODO Auto-generated catch block
			//e.printStackTrace();
		} catch (IllegalStateException e) {
			// TODO Auto-generated catch block
			//e.printStackTrace();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			//e.printStackTrace();
		}
	}
	/**
	 * This method sends a stopservice command to the DictationRecorderService. 
	 * The service saves the audio file, and sets the metadata in teh database.
	 * 
	 * This method queries teh database to get back the meta information about the recording.
	 * 
	 * Notes: if the service is stopped, and this method continues concurrently its highly possible that it wont 
	 * fetch the final info from the database. 
	 * 
	 * Consequences:
	 *  NOTCRUCIAL: the audio file will likely be the same as the file that was saved to the database when 
	 *  the service started recording, so the edit activity can simply set this as teh data for the media player.
	 *  By the time the javascript renders the play button, and the uesr clicks on play, the service will have saved
	 *  the audio file and finished. 
	 *  
	 *  POTENTIALLYPROBLEMATIC: the status message will most likley not contain any value for the length of the recording. so this variable
	 *  will not be useable until the databse is queried again. 
	 *  TODO schedule another queriy or create a listener for database updates and then query the database?
	 * 
	 * @return
	 */
	public String stopSaveRecording(){
		/*
		 * Stop recording service, it will save the audio to sdcard and database
		 */
		mRecordingNow=false;
		Intent intent = new Intent(this, DictationRecorderService.class);
		stopService(intent);
		/*
		 * Get the information out of the database once the database notifies its observers (which Editblog has a registered observer)
		 * that the database has been updated. 
		 */
		mAuBlogContentObserver.onChange(false);

		tracker.trackEvent(
	            "AuBlogLifeCycleEvent",  // Category
	            "Dictation",  // Action
	            "Audio recording of post:"+mPostId+" user clicked stop. This is the extracted time recorded (accurate depending on whether the contextobserver got back the database info: "+mTimeAudioWasRecorded/100+"sec: "+mAuBlogInstallId, // Label
	            350);       // Value
	
		/*
         * launch async notification service which sends file to transcription server.
         */
	   	mSendForTranscription=true;
	   	
        /*
         * Transcription possibilities:
         * 1. using googles not published speech API
         * 	http://src.chromium.org/viewvc/chrome/trunk/src/content/browser/speech/speech_recognition_request.cc?view=markup
         *  Perl example: http://mikepultz.com/2011/03/accessing-google-speech-api-chrome-11/
         *  Java example: ?
         * 2. using the Voice Recognition sample app, tweeked to automate the button to cut up audio chunks
         *   http://developer.android.com/resources/samples/ApiDemos/src/com/example/android/apis/app/VoiceRecognition.html
         *   http://developer.android.com/resources/articles/speech-input.html
         * 3. Sphinx project
         * 	http://cmusphinx.sourceforge.net/
         * 
         * Audio splitting based on silence
         * 1. c: https://github.com/taf2/audiosplit/graphs/languages
         * 
         * Code to do a voice recognition via google voice:
        try {
			URL url = new URL("https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&lang=en-US");
			
		} catch (MalformedURLException e) {
			// TODO Auto-generated catch block
			//e.printStackTrace();
			Toast.makeText(EditBlogEntryActivity.this, "The App cannot transcribe audio, maybe the Android has no network connection?"+e, Toast.LENGTH_SHORT).show();

		}
		Intent i = new Intent(EditBlogEntryActivity.this, AudioToText.class);
		//tell the i the mUri that is supposed to be published
		/*
		 * TODO, start activity for result 
		 * get the array of results, use some internal aublog logic to determine which is most likely and append the text into the blog content
		 
		startActivity(i);
         */
		
        
	   
		return "Attached "+mTimeAudioWasRecorded/100+" second recorded dictation.\n";
	}
	/**
	 * The audio time recorded is saved in the audiofile status message. This extracts it out of the staus. 
	 * Note: the time is most probably minimally longer than the actual audio time of the saved audio file. 
	 * 
	 * @param statusMessage a string delimited by ::: with the words "Attached a "+mTimeAudioWasRecorded/100+" second Recording.\n" somewhere inside
	 * @return the Long value in miliseconds of the recording. Or 0 if no message was found.
	 */
	public Long extractTimeRecordedFromAudioFileStatus(String statusMessage){
		String[] temp;
		String delimiter = ":::";
		String lmTimeAudioWasRecorded="0";
		temp = statusMessage.split(delimiter);
		for(int i = 0; i< temp.length ; i++){
			if(temp[i].contains("Attached a ")){
				lmTimeAudioWasRecorded=temp[i];
				lmTimeAudioWasRecorded.replace("Attached a ","");
				lmTimeAudioWasRecorded.replace(" second Recording.\n","");
			}
		}
		Long timeAudioWasRecorded= Long.parseLong(lmTimeAudioWasRecorded);
		return timeAudioWasRecorded=timeAudioWasRecorded*100;
	}
	public Long returnTimeRecorded(){
		//Long timePassed = (System.currentTimeMillis()-mStartTime)/1000;
		
		return mTimeAudioWasRecorded;//timePassed+"min";
	}
	
	/*
	private void saveStateToActivity(String strTitle, String strContent, String strLabels){
    	if(mDeleted == true){
    		return;
    	}
    	if (!(mPostTitle.equals(strTitle)) ){
    		flagDraftTreeAsNeedingToBeReGenerated();
    	}
    	mPostContent= strContent;
    	mPostTitle=strTitle;
    	mPostLabels=strLabels;
    	if (mLongestEverContent.length() < (mPostTitle+mPostContent+mPostLabels).length() ){
			mLongestEverContent=mPostTitle+mPostContent+mPostLabels;
		}
    }*/
	/**
	 * Accepts title content and labels (probably from the javascript), saves those to the database along with the audiofile info
	 */
	private void saveAsSelfToDB(String strTitle, String strContent, String strLabels){
		//TODO changing so that whatever value is sent in, is saved for title content and labels
		if (mDeleted == true){
			return ;
		}
    	try{
    		if (mLongestEverContent.length() < (strTitle+strContent+strContent).length() ){
    			mLongestEverContent=strTitle+strContent+strContent;
    		}
//    		if ( mLongestEverContent.length() <=3 ){ 
//    			//delete the entry the blog entry is completely empty, or if the user never anything. this should prevent having empty entrys in the database, but keep entries that are zeroed out and had content before
//    			deleteEntry(mUri);
//    		}
    		else{
	    		ContentValues values = new ContentValues();
	        	values.put(AuBlogHistory.ENTRY_TITLE, strTitle);
	        	values.put(AuBlogHistory.ENTRY_CONTENT, strContent);
	        	values.put(AuBlogHistory.ENTRY_LABELS, strLabels);
	        	values.put(AuBlogHistory.TIME_EDITED, Long.valueOf(System.currentTimeMillis()));
	        	values.put(AuBlogHistory.AUDIO_FILE, mAudioResultsFile);
	        	values.put(AuBlogHistory.AUDIO_FILE_STATUS, mAudioResultsFileStatus);
	    		getContentResolver().update(mUri, values,null, null);
	    		Log.d(TAG, "Post saved to database.");
	    		//Toast.makeText(EditBlogEntryActivity.this, "Post " +mUri.getLastPathSegment()+" saved as self to database\n\nTitle: "+mPostTitle+"\nLabels: "+mPostLabels+"\n\nPost: "+mPostContent, Toast.LENGTH_LONG).show();
    		}
    	} catch (SQLException e) {
    		// Log.e(TAG,"SQLException (createPost(title, content))");
    		tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Database connection problem "+e+" : "+mAuBlogInstallId, // Label
    	            3201);       // Value
    		Toast.makeText(EditBlogEntryActivity.this, "Database connection problem "+e, Toast.LENGTH_LONG).show();
    	} catch (Exception e) {
    		// Log.e(TAG, "Exception: " + e.getMessage());
    		tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "exception "+e+" : "+mAuBlogInstallId, // Label
    	            3202);       // Value
    		Toast.makeText(EditBlogEntryActivity.this, "exception "+e, Toast.LENGTH_LONG).show();
    	}
	}
	private void saveAsDaughterToDB(String strTitle, String strContent, String strLabels){
    	try{
    		/*
    		 * Create daughter
    		 * TODO: create daughter always with no audio file. if there is an audio file it is added by the recorder service
    		 */
        	ContentValues daughterValues = new ContentValues();
        	daughterValues.put(AuBlogHistory.ENTRY_TITLE, strTitle);
        	daughterValues.put(AuBlogHistory.ENTRY_CONTENT, strContent);
        	daughterValues.put(AuBlogHistory.ENTRY_LABELS, strLabels);
        	daughterValues.put(AuBlogHistory.TIME_EDITED, Long.valueOf(System.currentTimeMillis()));
        	daughterValues.put(AuBlogHistory.AUDIO_FILE, mAudioResultsFile);
        	daughterValues.put(AuBlogHistory.AUDIO_FILE_STATUS, mAudioResultsFileStatus);
        	if ( (strTitle+strContent+strLabels).length() <= 0 ){
        		if (mLongestEverContent.length() <= 0 ){
        			saveAsSelfToDB(strTitle, strContent, strLabels);
        			tracker.trackEvent(
            	            "AuBlogLifeCycleEvent",  // Category
            	            "Save",  // Action
            	            "save as self:no new text: "+mAuBlogInstallId, // Label
            	            311);       // Value
        			return;
        		}
        		//if the user blanked out the blog entry, probably they are restarting from scratch so set the parent to zero node
        		daughterValues.put(AuBlogHistory.PARENT_ENTRY, AuBlogHistoryDatabase.ROOT_ID_DEFAULT);
        		
    		}else{
    			daughterValues.put(AuBlogHistory.PARENT_ENTRY, mUri.getLastPathSegment());
    		}
    		Uri daughterUri = getContentResolver().insert(AuBlogHistory.CONTENT_URI, daughterValues);
    		tracker.trackEvent(
    	            "AuBlogLifeCycleEvent",  // Category
    	            "Save",  // Action
    	            "save as daughter: "+mAuBlogInstallId, // Label
    	            312);       // Value
    		/*
    		 * Save parent but just tell it has a daughter, dont put the new values into its entry.
    		 * It should stay the way it was last saved when the user pushed the save button.
    		 */
//    		ContentValues parentValues = new ContentValues();
//    		parentValues.put(AuBlogHistory.DELETED,"true");
//    		getContentResolver().update(mUri, parentValues,null, null);
    		/*
    		 * Set the daughter to the active mUri, and reinitialize the state values to the daughers values
    		 */
    		mPostParent=mUri.getLastPathSegment();
    		//Toast.makeText(EditBlogEntryActivity.this, "Post "+daughterUri.getLastPathSegment()+" saved as daugher of: " +mUri.getLastPathSegment()+" to database\n\nTitle: "+mPostTitle+"\nLabels: "+mPostLabels+"\n\nPost: "+mPostContent, Toast.LENGTH_LONG).show();
    		mUri=daughterUri;
    		getIntent().setData(mUri);
    		saveAsSelfToDB(strTitle, strContent, strLabels);
    		
    		/*
    		 * If this save to database includes a new audio file, send it for transcription with this 
    		 * daughter uri to edit when it comes back to the edit activity with transcription content.
    		 */
    		if(mSendForTranscription ==true){
    			Intent intent = new Intent(this, NotifyingTranscriptionIntentService.class);
	            intent.putExtra(NotifyingTranscriptionService.EXTRA_AUDIOFILE_FULL_PATH, mAudioResultsFile);
	            intent.putExtra(NotifyingTranscriptionService.EXTRA_SPLIT_TYPE, NotifyingTranscriptionService.SPLIT_ON_SILENCE);
	            intent.putExtra(NotifyingTranscriptionIntentService.EXTRA_CORRESPONDING_DRAFT_URI_STRING, mUri.toString());
	            startService(intent); 
	            mSendForTranscription = false;
	            mAudioResultsFileStatus="recordingsenttotranscriptionservice";
            }
    		mDeleted=false;
    		mPostId=mUri.getLastPathSegment();
    		
//    		mTts.speak("The text to speech is working. This means I can talk to you so that you don't have to look at the screen.",
//    		        TextToSpeech.QUEUE_FLUSH,  // Drop all pending entries in the playback queue.
//    		        null);
    		
    		Log.d(TAG, "Post saved to database.");
    	} catch (SQLException e) {
    		tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Database connection problem "+e+" : "+mAuBlogInstallId, // Label
    	            3101);       // Value
    		// Log.e(TAG,"SQLException (createPost(title, content))");
    		Toast.makeText(EditBlogEntryActivity.this, "Database connection problem "+e, Toast.LENGTH_LONG).show();
    	} catch (Exception e) {
    		// Log.e(TAG, "Exception: " + e.getMessage());
    		
    		//Toast.makeText(EditBlogEntryActivity.this, "Exception "+e, Toast.LENGTH_LONG).show();
    		tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Unknown exception "+e+" : "+mAuBlogInstallId, // Label
    	            3102);       // Value
    	}
    	flagDraftTreeAsNeedingToBeReGenerated();

	}
	private void flagDraftTreeAsNeedingToBeReGenerated(){
		/*
    	 * Flag the draft tree as needing to be regenerated
    	 */
    	SharedPreferences prefs = getSharedPreferences(PreferenceConstants.PREFERENCE_NAME, MODE_PRIVATE);
    	SharedPreferences.Editor editor = prefs.edit();
    	editor.putBoolean(PreferenceConstants.PREFERENCE_DRAFT_TREE_IS_FRESH,false);
    	editor.commit();
	}
	public boolean onKeyDown(int keyCode, KeyEvent event) {
		if (keyCode == KeyEvent.KEYCODE_BACK) {
//			mWebView.loadUrl("javascript:savePostToDB()");
		}
//		if (keyCode == KeyEvent.KEYCODE_MENU) {
//			int tmp1 = 0, tmp2 = 0;
//			tmp1 = postContent.getSelectionStart();
//			tmp2 = postContent.getSelectionEnd();
//			selectionStart = Math.min(tmp1, tmp2);
//			selectionEnd = Math.max(tmp1, tmp2);
//		}
		return super.onKeyDown(keyCode, event);
	}
    
	
    /**
     * Provides a hook for calling "alert" from javascript. Useful for
     * debugging your javascript.
     
    final class MyWebChromeClient extends WebChromeClient {
        @Override
        public boolean onJsAlert(WebView view, String url, String message, JsResult result) {
            Log.d(TAG, message);
            result.confirm();
            return true;
        }
        
    }*/

    @Override
	public boolean onCreateOptionsMenu(Menu menu) {
		// Hold on to this
		mMenu = menu;
		// Inflate the currently selected menu XML resource.
		MenuInflater inflater = getMenuInflater();
		inflater.inflate(R.menu.drafts_tree_menu, menu);
		return true;
	}
	@Override
	public boolean onOptionsItemSelected(MenuItem item) {
		switch (item.getItemId()) {
		// For "Title only": Examples of matching an ID with one assigned in
		//                   the XML
		case R.id.open_settings:
			tracker.trackPageView("/settingsScreen");
			tracker.trackEvent(
		            "Clicks",  // Category
		            "Button",  // Action
		            "clicked settings in the edit blog entry menu: "+mAuBlogInstallId, // Label
		            34);       // Value
			Intent i = new Intent(getBaseContext(),	SetPreferencesActivity.class);
			startActivity(i);
			return true;
		case R.id.new_entry:
			tracker.trackPageView("/editBlogEntryScreen");
			tracker.trackEvent(
		            "Clicks",  // Category
		            "Button",  // Action
		            "clicked new entry in the edit blog entry menu: "+mAuBlogInstallId, // Label
		            32);       // Value

			Intent intent = new Intent(getBaseContext(), EditBlogEntryActivity.class);

			Uri uri = getContentResolver().insert(AuBlogHistory.CONTENT_URI,
					null);
			// If we were unable to create a new blog entry, then just finish
			// this activity. A RESULT_CANCELED will be sent back to the
			// original activity if they requested a result.
			if (uri == null) {
				Log.e(TAG, "Failed to insert new blog entry into "
						+ getIntent().getData());
				Toast.makeText(
						EditBlogEntryActivity.this,
						"Failed to insert new blog entry into the database. You can go to your devices settings, choose Aublog and click Clear data to re-create the database."
								+ getIntent().getData() + " with this uri"
								+ AuBlogHistory.CONTENT_URI, Toast.LENGTH_LONG)
						.show();
				tracker.trackEvent(
			            "Database",  // Category
			            "Bug",  // Action
			            "cannot create new entry in the edit blog entry menu: "+mAuBlogInstallId, // Label
			            30);       // Value

			} else {
				intent.setData(uri);
				startActivity(intent);
				finish();
			}
			return true;
		default:
			// Do nothing

			break;
		}
		return false;
	}
}