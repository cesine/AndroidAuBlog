package ca.ilanguage.aublog.ui;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.Locale;

import com.google.android.apps.analytics.GoogleAnalyticsTracker;

import android.app.Activity;
import android.content.ContentValues;
import android.content.Context;
import android.content.Intent;
import android.content.SharedPreferences;
import android.content.res.Configuration;
import android.database.ContentObserver;
import android.database.Cursor;
import android.database.SQLException;
import android.media.AudioManager;
import android.media.MediaPlayer;
import android.media.MediaRecorder;
import android.net.Uri;
import android.os.Build;
import android.os.Bundle;
import android.os.Handler;
import android.speech.tts.TextToSpeech;
import android.util.Log;
import android.view.KeyEvent;
import android.view.Menu;
import android.view.MenuInflater;
import android.view.MenuItem;
import android.webkit.JsResult;
import android.webkit.WebChromeClient;
import android.webkit.WebSettings;
import android.webkit.WebView;
import android.webkit.WebViewClient;
import android.widget.Toast;

import ca.ilanguage.aublog.R;
import ca.ilanguage.aublog.db.AuBlogHistoryDatabase;
import ca.ilanguage.aublog.db.AuBlogHistoryDatabase.AuBlogHistory;
import ca.ilanguage.aublog.preferences.NonPublicConstants;
import ca.ilanguage.aublog.preferences.PreferenceConstants;
import ca.ilanguage.aublog.preferences.SetPreferencesActivity;
import ca.ilanguage.aublog.service.DictationRecorderService;
import ca.ilanguage.aublog.service.NotifyingTranscriptionIntentService;
import ca.ilanguage.aublog.service.NotifyingTranscriptionService;

/**
 * Demonstrates how to embed a WebView in your activity. Also demonstrates how
 * to have javascript in the WebView call into the activity, and how the activity 
 * can invoke javascript.
 * <p>
 * In this example, clicking on the android in the WebView will result in a call into
 * the activities code in {@link DemoJavaScriptInterface#clickOnAndroid()}. This code
 * will turn around and invoke javascript using the {@link WebView#loadUrl(String)}
 * method.
 * <p>
 * Obviously all of this could have been accomplished without calling into the activity
 * and then back into javascript, but this code is intended to show how to set up the 
 * code paths for this sort of communication.
 *
 */
public class EditBlogEntryActivity extends Activity implements TextToSpeech.OnInitListener {

	GoogleAnalyticsTracker tracker;
	private String mAuBlogInstallId;
    private static final String TAG = "CreateBlogEntryActivity";
    /** Talk to the user */
    private TextToSpeech mTts;
    private Menu mMenu;
    private String mBloggerAccount;
	private String mBloggerPassword;
    private Long mTimeAudioWasRecorded;
    private String mAudioSource;//bluetooth(record,play), phone(recordmic, play earpiece) for privacy, speaker(record mic, play speaker)
    private Boolean mUseBluetooth;
    private Boolean mUsePhoneEarPiece;
    

    private AudioManager mAudioManager;
    
    private MediaPlayer mMediaPlayer;
    Boolean mRecordingNow;
    Boolean mPlayingNow;
    private Boolean mReadBlog;
    private Boolean mSendForTranscription = false;
    //DONE adde recording logic 
    //DONE figure out the problems with the account database,decoup0le the account database with the blog entry screen
    
	//uri of the entry being edited.
	private Uri mUri;
	private Cursor mCursor;
	public AuBlogHistoryContentObserver mAuBlogContentObserver;
	
	int selectionStart;
	int selectionEnd;
	//DONE removed member varibles which are only changed in javascript title, content and labels
	String mTitleContentLabel="";
	String mPostParent ="";
	String mPostId ="";
	String mAudioResultsFile;
	String mAudioResultsFileStatus;
	//Boolean mFreshEditScreen;
	private Boolean mDeleted = false;
	String mLongestEverContent ="";
	private  String[] PROJECTION = new String[] {
		AuBlogHistory._ID, //0
		AuBlogHistory.ENTRY_TITLE, 
		AuBlogHistory.ENTRY_CONTENT, //2
		AuBlogHistory.ENTRY_LABELS,
		AuBlogHistory.PUBLISHED, //4
		AuBlogHistory.DELETED,
		AuBlogHistory.PARENT_ENTRY, //6
		AuBlogHistory.PUBLISHED_IN,
		AuBlogHistory.TIME_CREATED,//8
		AuBlogHistory.LAST_MODIFIED,  //this is a value generated by a database save LAST_EDITED is a value generated by the EditBlogEntryActivity
		AuBlogHistory.AUDIO_FILE,//10
		AuBlogHistory.AUDIO_FILE_STATUS
	};
	
	
	private WebView mWebView;
	
	private class AuBlogHistoryContentObserver extends ContentObserver {

		public AuBlogHistoryContentObserver(){
			super(null);
		}
		
		@Override
		public void onChange(boolean selfChange) {
			
			super.onChange(selfChange);
			getAudioFileDataOutOfDatabase();
		}
		
	}
    
    //implement on Init for the text to speech
	public void onInit(int status) {
		if (status == TextToSpeech.SUCCESS) {
			// Set preferred language to US english.
			// Note that a language may not be available, and the result will
			// indicate this.
			int result = mTts.setLanguage(Locale.US);
			// Try this someday for some interesting results.
			// int result mTts.setLanguage(Locale.FRANCE);
			if (result == TextToSpeech.LANG_MISSING_DATA
					|| result == TextToSpeech.LANG_NOT_SUPPORTED) {
				// Language data is missing or the language is not supported.
				Log.e(TAG, "Language is not available.");
				//Toast.makeText(EditBlogEntryActivity.this, "The English TextToSpeech isn't installed, you can go into the \nAndroid's settings in the \nVoice Input and Output menu to turn it on. ", Toast.LENGTH_LONG).show();

			} else {
				//everything is working.
			}
		} else {
			// Initialization failed.
			tracker.trackEvent(
		            "DependantPackages",  // Category
		            "FileManager",  // Action
		            "user doesnt have TTS, in the init failed section, didnt take them to package manager: "+mAuBlogInstallId, // Label
		            301);       // Value
        	
			Log.e(TAG, "Sorry, I can't talk to you because I could not initialize TextToSpeech.");
		}
	}
	/**
	 * Important Potential Hazard of Bluetooth and changing Audio Settings in the middle of an activity:
	 * 
	 * Using the bluetooth for audio in 2.2 has a bug which has been documented here:
	 * http://code.google.com/p/android/issues/detail?id=9503
	 * Bottom line: this activity can crash the phone if the user turns off the bluetooth device in this activity, in Android 2.2.  
	 * 
	 * 
	 * - Steps to reproduce the problem (including sample code if appropriate).
		
		using startBluetoothSco/stopBluetoothSco on Android 2.2 (FRF85B)
		don't exit the app that called them
		then disable or disconnect link to bluetooth headset
		
		- What happened.
		
		The system rebooted because of a crash in AudioService.java. When the headset gets disconnected it tries to call unlinkToDeath with "noSuchElementExceptions: death link does not exist"
		
		- What you think the correct behavior should be.
		
		When calling stopBluetoothSco the ScoClient should get removed from the list of ScoClients.
		
		
	 */
	/**
	 * Re-checks the audio settings and the installid from the settings.
	 * 
	 */
	private void recheckAublogSettings(){
    	SharedPreferences prefs = getSharedPreferences(PreferenceConstants.PREFERENCE_NAME, MODE_PRIVATE);
		/*
		 * set the installid for appending to the labels
		 */
		mAuBlogInstallId = prefs.getString(PreferenceConstants.AUBLOG_INSTALL_ID, "0");

		mReadBlog = prefs.getBoolean(PreferenceConstants.PREFERENCE_SOUND_ENABLED, true);
	    mUseBluetooth = prefs.getBoolean(PreferenceConstants.PREFERENCE_USE_BLUETOOTH_AUDIO, false);
	    mUsePhoneEarPiece = prefs.getBoolean(PreferenceConstants.PREFERENCE_USE_PHONE_EARPIECE_AUDIO, false);
	   /*
	    * Sets audio values to normal
	    */
	    mAudioManager.setMode(AudioManager.MODE_NORMAL);
        mAudioManager.setSpeakerphoneOn(true);
	    if(mUseBluetooth){
			/*
	    	 * As the SCO connection establishment can take several seconds, applications should not rely on the connection to be available when the method returns but instead register to receive the intent ACTION_SCO_AUDIO_STATE_CHANGED and wait for the state to be SCO_AUDIO_STATE_CONNECTED.
	    	 Even if a SCO connection is established, the following restrictions apply on audio output streams so that they can be routed to SCO headset: - the stream type must be STREAM_VOICE_CALL - the format must be mono - the sampling must be 16kHz or 8kHz

				Similarly, if a call is received or sent while an application is using the SCO connection, the connection will be lost for the application and NOT returned automatically when the call ends.
			* Notes:
			* Use of the blue tooth does not affect the ability to recieve a call while using the app,
			* However, the app will not have control of hte bluetooth connection when teh phone call comes back. The user must exit the Edit Blog activity.
			* 
	    	 */
	    	mAudioManager.startBluetoothSco();
	    	mAudioManager.setSpeakerphoneOn(false);
	    	mAudioManager.setBluetoothScoOn(true);
	    	setVolumeControlStream(AudioManager.STREAM_VOICE_CALL);
	    	mAudioManager.setMode(AudioManager.MODE_IN_CALL);
	    }
		if(mUsePhoneEarPiece){
			mAudioManager.setSpeakerphoneOn(false);
	    	setVolumeControlStream(AudioManager.STREAM_VOICE_CALL);
	    	mAudioManager.setMode(AudioManager.MODE_IN_CALL);
	    }
    	/*
    	 * then the app can use the media player as usual
    	 */
    }
    /**
     * Moved to onResume: all the database access and calls to javascript to fill the webview
     * with information from the database.
     * 
     * See onCreate for initialization of member objects.
     */
    @Override
	protected void onResume() {
    	super.onResume();
    	recheckAublogSettings();
	    /**
         * Get the uri which was sent to the CreateBlogActivity, put the data into the fields.
         */
    	//String fillFromActivityValues="";
    	String title;
    	String content;
    	String label;
        mUri = getIntent().getData();
        mCursor = managedQuery(mUri, PROJECTION, null, null, null);
        if (mCursor != null) {
			// Requery in case something changed while paused (such as the title)
			mCursor.requery();
            // Make sure we are at the one and only row in the cursor.
            mCursor.moveToFirst();
			try {
					title =mCursor.getString(1);
					content =mCursor.getString(2);
					label= mCursor.getString(3);
					mTitleContentLabel=title+":::--"+content+":::--"+label;
					mTitleContentLabel.replaceAll("\"", "\\\"");
					mPostId = mCursor.getString(0);
					mPostParent = mCursor.getString(6);
					getAudioFileDataOutOfDatabase();
					if("0".equals(mCursor.getString(5))){ 
						mDeleted=false;
					}else{
						mDeleted=true;
					}

			} catch (IllegalArgumentException e) {
				// Log.e(TAG, "IllegalArgumentException (DataBase failed)");
				tracker.trackEvent(
			            "Database",  // Category
			            "Bug",  // Action
			            "Retrieval from DB failed with an illegal argument exception "+e+" : "+mAuBlogInstallId, // Label
			            301);       // Value
				Toast.makeText(EditBlogEntryActivity.this, "Retrieval from DB failed with an illegal argument exception "+e, Toast.LENGTH_LONG).show();
			} catch (Exception e) {
				// Log.e(TAG, "Exception (DataBase failed)");
				tracker.trackEvent(
			            "Database",  // Category
			            "Bug",  // Action
			            "The cursor returned is "+e+" : "+mAuBlogInstallId, // Label
			            302);       // Value
				//Toast.makeText(EditBlogEntryActivity.this, "The cursor returned is "+e, Toast.LENGTH_LONG).show();
			}
        }else{
			//this should never be executed
		}
		mWebView.loadUrl("file:///android_asset/edit_blog_entry_wysiwyg.html");
		//mWebView.loadUrl("javascript:fillTitleContentLabels("+fillFromActivityValues+")");
		//mWebView.loadUrl("javascript:fillTitleContentLabels(\"About me:::--Your blog's About Me page should not be overlooked. It's an essential tool to establish who you are as a blogger and help readers understand what your blog is about. Simply listing your name and contact information is not enough. Sell yourself and your blog on your About Me page, and make readers believe you're not only an expert in your blog's topic but your blog is also the place for people to find information about your topic on the web. From <a href='http://weblogs.about.com/od/partsofablog/qt/AboutPage.htm'>About.com</a>:::--about me\")");
		mWebView.loadUrl("javascript:displayAudioResultsFileStatus()");
		
	}
    /**
     * onCreate is being used to initialize all member objects (such as media player etc). 
     * 
     * See onResume for anything to do with UI content such as preparing the webview and the
     * data out of the database to go into it. 
     */
    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        mTts = new TextToSpeech(this, this);
        mAudioManager = (AudioManager)getSystemService(Context.AUDIO_SERVICE);
        mMediaPlayer = new MediaPlayer();
        mMediaPlayer.setLooping(true);
        mRecordingNow = false;
        tracker = GoogleAnalyticsTracker.getInstance();
	    // Start the tracker in manual dispatch mode...
	    tracker.start(NonPublicConstants.NONPUBLIC_GOOGLE_ANALYTICS_UA_ACCOUNT_CODE, 20, this);

        mAuBlogContentObserver = new AuBlogHistoryContentObserver();
        getContentResolver().registerContentObserver(AuBlogHistory.CONTENT_URI, true, mAuBlogContentObserver);
           
        setContentView(R.layout.main_webview);
        mWebView = (WebView) findViewById(R.id.webview);
        //http://stackoverflow.com/questions/2835556/whats-the-difference-between-setwebviewclient-vs-setwebchromeclient
        mWebView.setWebChromeClient(new MyWebChromeClient()); 
        mWebView.setWebViewClient(new WebViewClient()); 
        mWebView.addJavascriptInterface(new JavaScriptInterface(this), "Android");
        WebSettings webSettings = mWebView.getSettings();
        webSettings.setSaveFormData(true);
        webSettings.setJavaScriptEnabled(true);    		
    }
    /**
     * This contains functions which are availible to the javascript in the webview
     * It is called using the name in the line:
     *  mWebView.addJavascriptInterface(new JavaScriptInterface(this), "Android");
     *  
     * So for example, the button in the javascript of the webview, would have as its onClick()
     * Android.stopRecord()
     * 
     * @author gina
     *
     */
    public class JavaScriptInterface {
        Context mContext;

        /** Instantiate the interface and set the context */
        JavaScriptInterface(Context c) {
            mContext = c;
        }
        public void showToast(String toast) {
            Toast.makeText(mContext, toast, Toast.LENGTH_SHORT).show();
        }
        public void readToTTS(String message){
        	recheckAublogSettings(); //if user turned off tts dont read it
        	if(mReadBlog){
        		readTTS(message);
        	}else{
        		tracker.trackEvent(
        	            "TTS",  // Category
        	            "notUsed",  // Action
        	            "there was a message that was not read via TTS because it is off in the settings: "+message+" : "+mAuBlogInstallId, // Label
        	            362);       // Value
        	}
        }
        /**
         * A wrapper for the edit blog activity's method which creates a new audio file name using the posts title
         * and sends it off to the DictaitonRecorder service to be recorded. It returns a status message.
         * @param postTitle The current title of the blog post, it will show up in the audio file's name
         * @return an internal status message
         */
        public String startToRecord(String postTitle){
        	return beginRecording(postTitle);
        }
        /**
         * A wrapper which stops the Dictation recorder service and (later) gets the 
         * audio file's meta data from the database once the service has saved it. 
         * @return an internal status message
         */
        public String stopRecord(){
        	return stopSaveRecording();
        }
        /**
         * A wrapper for the play or pause audio function in the edit blog activity
         * @return a string which can be used for the button (ie Play if the media player is paused or stopped, or Pause if the media player is playing)
         */
        public String playOrPauseAudio(){
        	return playOrPauseAudioFile();
        }
        /**
         * returns a Long of the time recorded. The time recorded is extracted out of the audiofile status message when 
         * the audio file data is fetched. this happens in each onstart, and also after the user clicks Stop dictation.
         * This can be used to find out if the blog post has an audio file (it will return a value greater than 0).
         * 
         * @return time in milliseconds of the recording
         */
        public Long getTimeRecorded(){
        	return returnTimeRecorded();
        }
        public String getAudioResultsFileStatus(){
        	if (mAudioResultsFileStatus != null){
        		return mAudioResultsFileStatus;
        	}else{
        		return "No audio results file status found.";
        	}
        }
        /**
         * Wrapper for the edit blog activity save post as self to the database method
         * @param strTitle
         * @param strContent
         * @param strLabels
         */
        public void savePostToDB(String strTitle, String strContent, String strLabels){
        	tracker.trackEvent(
    	            "AuBlogLifeCycleEvent",  // Category
    	            "saveSTate",  // Action
    	            "Javascript was saved to database "+strTitle+" : "+strLabels+" : "+strContent+" : "+mAuBlogInstallId, // Label
    	            34);       // Value
        	saveAsSelfToDB(strTitle, strContent, strLabels);
        }
        /**
         * Wrapper for the edit blog activty save post as a daughter to the database method. 
         * 
         * @param strTitle
         * @param strContent
         * @param strLabels
         */
        public void savePostAsDaughter(String strTitle, String strContent, String strLabels){
        	saveAsDaughterToDB(strTitle, strContent, strLabels);
        }
        public void fillFromDatabase(){
        	/**
             * Get the uri which was sent to the CreateBlogActivity, put the data into the fields.
             */
        	String fillFromActivityValues="";
        	
            mUri = getIntent().getData();
            mCursor = managedQuery(mUri, PROJECTION, null, null, null);
            if (mCursor != null) {
    			// Requery in case something changed while paused (such as the title)
    			mCursor.requery();
                // Make sure we are at the one and only row in the cursor.
                mCursor.moveToFirst();
    			try {
    					fillFromActivityValues=mCursor.getString(1)+":::--"+mCursor.getString(2)+":::--"+mCursor.getString(3);
    					fillFromActivityValues.replaceAll("\"", "\\\"");
    					mPostId = mCursor.getString(0);
    					mPostParent = mCursor.getString(6);
    					getAudioFileDataOutOfDatabase();
    					if("0".equals(mCursor.getString(5))){ 
    						mDeleted=false;
    					}else{
    						mDeleted=true;
    					}
    			} catch (IllegalArgumentException e) {
    				// Log.e(TAG, "IllegalArgumentException (DataBase failed)");
    				tracker.trackEvent(
    			            "Database",  // Category
    			            "Bug",  // Action
    			            "Retrieval from DB failed with an illegal argument exception "+e+" : "+mAuBlogInstallId, // Label
    			            301);       // Value
    				Toast.makeText(EditBlogEntryActivity.this, "Retrieval from DB failed with an illegal argument exception "+e, Toast.LENGTH_LONG).show();
    			} catch (Exception e) {
    				// Log.e(TAG, "Exception (DataBase failed)");
    				tracker.trackEvent(
    			            "Database",  // Category
    			            "Bug",  // Action
    			            "The cursor returned is "+e+" : "+mAuBlogInstallId, // Label
    			            302);       // Value
    				//Toast.makeText(EditBlogEntryActivity.this, "The cursor returned is "+e, Toast.LENGTH_LONG).show();
    			}
            }else{
    			//this should never be executed
    		}
    		mWebView.loadUrl("javascript:displayAudioResultsFileStatus()");
    		mWebView.loadUrl("javascript:fillTitleContentLabels(\""+fillFromActivityValues+"\")");
        }
        public void deletePost(String strTitle, String strContent, String strLabels){
        	saveAsSelfToDB(strTitle, strContent, strLabels);
        	deleteEntry(mUri);
        	finish();
        }
        /**
         * Saves the post as a daughter to the database, then calls the Publish activity, which then gets the info out of the database and publishes it.
         * TODO instead send Title, content, labels to publish activity as extras, and let it save them to the database too? otherwaise have to register a content listener in the publish activity. 
         * @param strTitle
         * @param strContent
         * @param strLabels
         */
        public void publishPost(String strTitle, String strContent, String strLabels){
        	//act like publish is both save+publish
        	saveAsDaughterToDB(strTitle, strContent, strLabels);
        	if ((strTitle.length() == 0)
        			|| (strTitle == null)
        			|| (strContent.length() == 0)
        			|| (strContent == null)) {
        		tracker.trackEvent(
			            "Publish",  // Category
			            "Error",  // Action
			            "displayed Toast:"+R.string.title_or_content_empty_error+" : "+mAuBlogInstallId, // Label
			            30);       // Value
        		Toast.makeText(EditBlogEntryActivity.this, R.string.title_or_content_empty_error, Toast.LENGTH_LONG).show();
        	} else {
        		SharedPreferences prefs = getSharedPreferences(PreferenceConstants.PREFERENCE_NAME, MODE_PRIVATE);
    		    mBloggerAccount = prefs.getString(PreferenceConstants.PREFERENCE_ACCOUNT, "see settings");
        		mBloggerPassword = prefs.getString(PreferenceConstants.PREFERENCE_PASSWORD, "see settings");
        		if( (!mBloggerAccount.contains("@") ) || mBloggerPassword.length()<4 ){
        			tracker.trackEvent(
    			            "Publish",  // Category
    			            "Error",  // Action
    			            "displayed Toast: Taking you to the settings to add a Blogger account.: "+mAuBlogInstallId, // Label
    			            302);       // Value
        			Toast.makeText(EditBlogEntryActivity.this, "No Blogger account found.\n\nTaking you to the settings to \n\nConfigure a Blogger account.", Toast.LENGTH_LONG).show();
        			Intent i = new Intent(EditBlogEntryActivity.this, SetPreferencesActivity.class);
            		startActivity(i);
        		}else{
        			tracker.setCustomVar(1, "Navigation Type", "Button click", 22);
	    			tracker.trackPageView("/publishBlogEntryScreen");
	    			Intent i = new Intent(EditBlogEntryActivity.this, PublishActivity.class);
	        		//tell the i the mUri that is supposed to be published
	        		//TODO either puth Title, Content, Labels as extras, or get them from the database. 
	    			//Currently: getting them from database 
	    			i.setData(mUri);
	        		startActivity(i);
	        		finish();
        		}
        	}
        }
    }//end javascript interface

	/**
	 * 
	 * Un-user-initiated saves do not create a new node in the draft tree
	 * (although, this can be changed by just calling saveAsDaugher here)
	 * 
	 * Rotate screen: save as self to database 
	 * Back button: save as self to database
	 * 
	 * // http://developer.android.com/guide/topics/media/index.html
	 * As you may know, when the user changes the screen orientation (or changes
	 * the device configuration in another way), the system handles that by
	 * restarting the activity (by default), so you might quickly consume all of
	 * the system resources as the user rotates the device back and forth
	 * between portrait and landscape, because at each orientation change, you
	 * create a new MediaPlayer that you never release.
	 * 
	 * DONE: playing and pausing is kept in the EditBlog activity, if the user
	 * rotates the screen or leaves it will probably not stop playing (the media player 
	 * is released in the onDestroy rather than the onPause. It will 
	 * stop playing when the user quits the edit blog activity. This is preferred. If
	 * the user wants to listen to their audio in the background they can use
	 * the normal Music player by opening the settings, and going to the audio
	 * folder.
	 * 
	 * DONE: refactored record as a service (foregrounded so that it will be
	 * less likely to be killed by android) Aublog will record a dictation until
	 * A: the user clicks stop in the EditBlogEntryActivity B: the users quits
	 * Aublog MainMenuActivity (ondestroy method) C: the user clicks on the
	 * notification, goes to the NotificationController and clicks Stop
	 * Recording. D: the system runs out of memory E: the service is killed by
	 * the system F: (aublog is killed by the system?) the service should be
	 * running in the same process id, so technically the service's ondestroy
	 * will be killed of aublog is killed.
	 * 
	 * Consequences: NEGATIVE: to find out if the audio file is valid, or how
	 * long it is, this EditBlogEntry now has to go to the database and the
	 * Sdcard, it cant know on its own. POSITIVE: the user can rotate the screen
	 * while dictating, which is very natural since they will pick up and put
	 * down the phone, walk around, maybe biking etc especially if the user is
	 * using a bluetooth.
	 */
	@Override
	protected void onPause() {
		mWebView.loadUrl("javascript:savePostToTheDB()");
		tracker.trackEvent("Event", // Category
				"Pause", // Action
				"event was paused: " + mAuBlogInstallId, // Label
				38); // Value
		super.onPause();
	}

	/**
	 * onPause is allways called before onDestroy, so all code in onPause is 
	 * also run here.
	 */
	@Override
	protected void onDestroy() {
		tracker.stop();
		/*
		 * If the mediaplayer exists or is playing, release it,
		 */
		if (mMediaPlayer != null) {
			mMediaPlayer.release();
			mMediaPlayer = null;
		}
		super.onDestroy();
	}
	/**
	 * This method simply marks a row in the database as deleted. This method is usually called 
	 * via the javascript interface (where the javascript also asks the last contents to be saved 
	 * as self to the database) hence, clicking on the Delete button in the javascript will make 
	 * two database calls.
	 * @param uri
	 */
	public void deleteEntry(Uri uri){
    	mDeleted = true;
    	/*
		 * Flag entry as deleted
		 */
    	tracker.trackEvent(
	            "AuBlogLifeCycleEvent",  // Category
	            "Delete",  // Action
	            "Entry was flagged as deleted in the database"+uri.getLastPathSegment()+" : "+mAuBlogInstallId, // Label
	            39);       // Value
		ContentValues values = new ContentValues();
		values.put(AuBlogHistory.DELETED,"1");//sets deleted flag to true
		getContentResolver().update(uri, values,null, null);
//		getContentResolver().delete(uri, null, null);
		flagDraftTreeAsNeedingToBeReGenerated();
		Toast.makeText(EditBlogEntryActivity.this, "Post " +uri.getLastPathSegment()+" deleted.", Toast.LENGTH_LONG).show();
		finish();
	}
	/*
	 * An wraper a call to the TTS engine, the logic of if the app should 
	 * read the blog entry (based on settings check box) is handled in 
	 * the javascript interface. 
	 * 
	 * General eyes-free interaction can still be read out to the user
	 * TODO add a settings item to turn off TTS completely vs TTS off for reading the blog entry. 
	 * (or should readign the blog entry just be in the javascript and the webview so the user
	 * can uncheck it if they want?)
	 */
	public void readTTS(String message){
		tracker.trackEvent(
	            "TTS",  // Category
	            "Use",  // Action
	            "spoke message: "+message+" : "+mAuBlogInstallId, // Label
	            361);       // Value
		mTts.speak(message,TextToSpeech.QUEUE_ADD, null);
	}
	public Boolean hasAudioFileAttached(){
		if (mAudioResultsFile.length() > 5 ){
			return true;
    	}else{
			return false;
    	}
	}
	/**
	 * Launches a service to record, it sends the service the name of the audio file to record
	 * The audio directory is created here if it doesn't exist.
	 * It also sends the service the current status message which is relatively empty. 
	 * (recording service started). This status is started fresh in the dictation recording service
	 * but the status generated here is sent as an extra, and saveable to the database to debug
	 * at which point the dictation recorder service does/does not kick in.
	 * 
	 * This method is generally called in the Record button in the javascript, example:
	 * 
	 * 
    		1. save what the user sees to this post.
    		
    		savePostToTheDB(); 
    		
    		2. create a new daughter post with the same content 
    		so that the edits teh user makes between turning on the recording 
    		and stopping the reocording go with the recording. 
    		
    		savePostAsDaughterToDB(); 
    		
    		3. start the recording
    		
    		Android.startToRecord(document.getElementById('f-title').value);
	 * 
	 * @return an internal status message
	 */
	public String beginRecording(String postTitle){
		mAudioResultsFileStatus = "Recording service started in Edit activity";
		String dateString = (String) android.text.format.DateFormat.format("yyyy-MM-dd_hh.mm", new java.util.Date());
		dateString = dateString.replaceAll("/","-");
		mAudioResultsFile = PreferenceConstants.OUTPUT_AUBLOG_DIRECTORY+"audio/";
		new File(mAudioResultsFile).mkdirs();
		mAudioResultsFile=mAudioResultsFile+mAuBlogInstallId+"_"+dateString+"_"+System.currentTimeMillis()+"_"+postTitle+".mp3"; 
		mAudioResultsFile=mAudioResultsFile.replaceAll(" ","-");
		mRecordingNow = true;
		Intent intent = new Intent(this, DictationRecorderService.class);
		/*
		 * warning: this uri might not be fresh (ie, might not be the daughter uri...which we need to attach the audio to the blog entry.
		 */
	 	intent.setData(mUri);
	 	intent.putExtra(DictationRecorderService.EXTRA_AUDIOFILE_FULL_PATH, mAudioResultsFile);
	    intent.putExtra(DictationRecorderService.EXTRA_AUDIOFILE_STATUS, mAudioResultsFileStatus);
	    startService(intent);
		return "Recording...";
	}
	/**
	 * A function which starts or pauses the media player.
	 * The media player is run in a loop so the user only has two options (Play,Pause) not three (Play,Pause,Stop)
	 * This design choice was made so that the user can transcribe their dictation. If they would like to listen to the audio they can 
	 * open the AuBlog settings to go to the AuBlog folder (its easy to find, its in the root of the SDCard) and play their dictations using the music player.
	 * Users can also use the Music player to make a play list of their dictations if they would like to listen continously to their dictations rather than transcribe them.
	 * 
	 * @return A message for the button which is the oposite of its current state. (ie, if the player is paused, it returns Play, if the player is started, it returns Pause)
	 */
	public String playOrPauseAudioFile(){
		if(mMediaPlayer.isPlaying()){
			mMediaPlayer.pause();
			/* TODO rewind logic doesnt work
			 * //if its playing, pause and rewind ~4 seconds
			int rewindValue = 2;
			int startPlayingFromSecond =mMediaPlayer.getCurrentPosition();
			if ( startPlayingFromSecond <= rewindValue){
				startPlayingFromSecond=0;
			}else{
				startPlayingFromSecond = startPlayingFromSecond - rewindValue;
			}
			mMediaPlayer.seekTo(startPlayingFromSecond);
			mMediaPlayer.prepareAsync();
			*/
			return "Play";
		}else{
			//if its not playing, play it
		    try {
		    	mMediaPlayer.start();
			} catch (IllegalArgumentException e) {
				Log.e("Error reading file", e.toString());
			} catch (IllegalStateException e) {
				Log.e("Error reading file", e.toString());
			} 
			return "Pause";
		}
		
	}
	/**
	 * This method gets audio file information out of the database, if the 
	 * information contains a valid audiofilename, it will set up the play button 
	 * and the media player. 
	 */
	private void getAudioFileDataOutOfDatabase(){
		/*
	   	 * get data from database.
	   	 */
		// Requery in case something changed while paused (such as the title)
		mCursor.requery();
        // Make sure we are at the one and only row in the cursor.
        mCursor.moveToFirst();
		try {
			mAudioResultsFile = mCursor.getString(10);
			mAudioResultsFileStatus = mCursor.getString(11);
    		/*
    		 * Extract the time of the audio that was recorded.
    		 */
    		mTimeAudioWasRecorded =extractTimeRecordedFromAudioFileStatus(mAudioResultsFileStatus);
		} catch (IllegalArgumentException e) {
			tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Database connection IllegalArgumentException in extractingn audiofile info after stopping recording"+e+" : "+mAuBlogInstallId, // Label
    	            3101);       // Value
		} catch (Exception e) {
			tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Database connection Exception in extracting audiofile info after stopping recording"+e+" : "+mAuBlogInstallId, // Label
    	            3101);       // Value
		}
		/*
	   	 * assign this audio recording to the media player
	   	 */
	   	try {
	   		/*
	   		 * bug: was not changing the data source here, so decided to reset the audio player completely and
	   		 * reinitialize it
	   		 */
	   		if (mAudioResultsFile.length() > 5){
	   			if(mMediaPlayer != null){
	   				mMediaPlayer.release();
	   				mMediaPlayer = null;
	   			}		   		
		   		//TODO put this back in after done debuging refactoring recheckAublogSettings();//if audio settings have changed use the new ones.
		   		mWebView.loadUrl("javascript:displayPlayButton()");
		   		mMediaPlayer = new MediaPlayer();
		        mMediaPlayer.setLooping(true);
		   		mMediaPlayer.setDataSource(mAudioResultsFile);
				mMediaPlayer.prepareAsync();
	   		}
		} catch (IllegalArgumentException e) {
			Log.e("Error reading file", e.toString());
		} catch (IllegalStateException e) {
			Log.e("Error reading file", e.toString());
		} catch (IOException e) {
			Log.e("Error reading file", e.toString());
		}
	}
	/**
	 * This method sends a stopservice command to the DictationRecorderService. 
	 * The service saves the audio file, and sets the metadata in teh database.
	 * 
	 * This method queries teh database to get back the meta information about the recording.
	 * 
	 * Notes: if the service is stopped, and this method continues concurrently its highly possible that it wont 
	 * fetch the final info from the database. 
	 * 
	 * Consequences:
	 *  NOTCRUCIAL: the audio file will likely be the same as the file that was saved to the database when 
	 *  the service started recording, so the edit activity can simply set this as teh data for the media player.
	 *  By the time the javascript renders the play button, and the uesr clicks on play, the service will have saved
	 *  the audio file and finished. 
	 *  
	 *  POTENTIALLYPROBLEMATIC: the status message will most likley not contain any value for the length of the recording. so this variable
	 *  will not be useable until the databse is queried again. 
	 *  TODO schedule another queriy or create a listener for database updates and then query the database?
	 * 
	 * @return
	 */
	public String stopSaveRecording(){
		/*
		 * Stop recording service, it will save the audio to sdcard and database
		 */
		mRecordingNow=false;
		Intent intent = new Intent(this, DictationRecorderService.class);
		stopService(intent);
		/*
		 * Get the information out of the database once the database notifies its observers (which Editblog has a registered observer)
		 * that the database has been updated. 
		 */
		mAuBlogContentObserver.onChange(false);

		tracker.trackEvent(
	            "AuBlogLifeCycleEvent",  // Category
	            "Dictation",  // Action
	            "Audio recording of post:"+mPostId+" user clicked stop. This is the extracted time recorded (accurate depending on whether the contextobserver got back the database info: "+mTimeAudioWasRecorded/100+"sec: "+mAuBlogInstallId, // Label
	            350);       // Value
	
		/*
         * launch async notification service which sends file to transcription server.
         */
	   	mSendForTranscription=true;
	   	
        /*
         * Transcription possibilities:
         * 1. using googles not published speech API
         * 	http://src.chromium.org/viewvc/chrome/trunk/src/content/browser/speech/speech_recognition_request.cc?view=markup
         *  Perl example: http://mikepultz.com/2011/03/accessing-google-speech-api-chrome-11/
         *  Java example: ?
         * 2. using the Voice Recognition sample app, tweeked to automate the button to cut up audio chunks
         *   http://developer.android.com/resources/samples/ApiDemos/src/com/example/android/apis/app/VoiceRecognition.html
         *   http://developer.android.com/resources/articles/speech-input.html
         * 3. Sphinx project
         * 	http://cmusphinx.sourceforge.net/
         * 
         * Audio splitting based on silence
         * 1. c: https://github.com/taf2/audiosplit/graphs/languages
         * 
         * Code to do a voice recognition via google voice:
        try {
			URL url = new URL("https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&lang=en-US");
			
		} catch (MalformedURLException e) {
			// TODO Auto-generated catch block
			//e.printStackTrace();
			Toast.makeText(EditBlogEntryActivity.this, "The App cannot transcribe audio, maybe the Android has no network connection?"+e, Toast.LENGTH_SHORT).show();

		}
		Intent i = new Intent(EditBlogEntryActivity.this, AudioToText.class);
		//tell the i the mUri that is supposed to be published
		/*
		 * TODO, start activity for result 
		 * get the array of results, use some internal aublog logic to determine which is most likely and append the text into the blog content
		 
		startActivity(i);
         */

		return "Attached "+mTimeAudioWasRecorded/100+" second recorded dictation.\n";
	}
	/**
	 * The audio time recorded is saved in the audiofile status message. This extracts it out of the staus. 
	 * Note: the time is most probably minimally longer than the actual audio time of the saved audio file. 
	 * 
	 * @param statusMessage a string delimited by ::: with the words "Attached a "+mTimeAudioWasRecorded/100+" second Recording.\n" somewhere inside
	 * @return the Long value in miliseconds of the recording. Or 0 if no message was found.
	 */
	public Long extractTimeRecordedFromAudioFileStatus(String statusMessage){
		String[] temp;
		String delimiter = ":::";
		String lmTimeAudioWasRecorded="0";
		temp = statusMessage.split(delimiter);
		for(int i = 0; i< temp.length ; i++){
			if(temp[i].contains("Attached a ")){
				lmTimeAudioWasRecorded=temp[i];
				lmTimeAudioWasRecorded.replace("Attached a ","");
				lmTimeAudioWasRecorded.replace(" second Recording.\n","");
			}
		}
		Long timeAudioWasRecorded= Long.parseLong(lmTimeAudioWasRecorded);
		return timeAudioWasRecorded=timeAudioWasRecorded*100;
	}
	public Long returnTimeRecorded(){
		//Long timePassed = (System.currentTimeMillis()-mStartTime)/1000;
		
		return mTimeAudioWasRecorded;//timePassed+"min";
	}
	/**
	 * Accepts title content and labels (probably from the javascript), saves those to the database along with the audiofile info
	 */
	private void saveAsSelfToDB(String strTitle, String strContent, String strLabels){
		/*
		 * dont change entries that are flagged as deleted... if commented out: let users edit posts which are flagged as deleted.
		 * 
		 if (mDeleted == true){
			return ;
			}
		 */
		try{
    		if (mLongestEverContent.length() < (strTitle+strContent+strContent).length() ){
    			mLongestEverContent=strTitle+strContent+strContent;
    		}
//    		if ( mLongestEverContent.length() <=3 ){ 
//    			//delete the entry the blog entry is completely empty, or if the user never anything. this should prevent having empty entrys in the database, but keep entries that are zeroed out and had content before
//    			deleteEntry(mUri);
//    		}
    		else{
	    		ContentValues values = new ContentValues();
	        	values.put(AuBlogHistory.ENTRY_TITLE, strTitle);
	        	values.put(AuBlogHistory.ENTRY_CONTENT, strContent);
	        	values.put(AuBlogHistory.ENTRY_LABELS, strLabels);
	        	values.put(AuBlogHistory.TIME_EDITED, Long.valueOf(System.currentTimeMillis()));
	        	values.put(AuBlogHistory.AUDIO_FILE, mAudioResultsFile);
	        	values.put(AuBlogHistory.AUDIO_FILE_STATUS, mAudioResultsFileStatus);
	    		getContentResolver().update(mUri, values,null, null);
	    		Log.d(TAG, "Post saved to database.");
	    	}
    	} catch (SQLException e) {
    		// Log.e(TAG,"SQLException (createPost(title, content))");
    		tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Database connection problem "+e+" : "+mAuBlogInstallId, // Label
    	            3201);       // Value
    		Toast.makeText(EditBlogEntryActivity.this, "Database connection problem "+e, Toast.LENGTH_LONG).show();
    	} catch (Exception e) {
    		// Log.e(TAG, "Exception: " + e.getMessage());
    		tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "exception "+e+" : "+mAuBlogInstallId, // Label
    	            3202);       // Value
    		Toast.makeText(EditBlogEntryActivity.this, "exception "+e, Toast.LENGTH_LONG).show();
    	}
	}
	private void saveAsDaughterToDB(String strTitle, String strContent, String strLabels){
    	try{
    		/*
    		 * Create daughter
    		 * TODO: create daughter always with no audio file. if there is an audio file it is added by the recorder service
    		 */
        	ContentValues daughterValues = new ContentValues();
        	daughterValues.put(AuBlogHistory.ENTRY_TITLE, strTitle);
        	daughterValues.put(AuBlogHistory.ENTRY_CONTENT, strContent);
        	daughterValues.put(AuBlogHistory.ENTRY_LABELS, strLabels);
        	daughterValues.put(AuBlogHistory.TIME_EDITED, Long.valueOf(System.currentTimeMillis()));
        	daughterValues.put(AuBlogHistory.AUDIO_FILE, mAudioResultsFile);
        	daughterValues.put(AuBlogHistory.AUDIO_FILE_STATUS, mAudioResultsFileStatus);
        	if ( (strTitle+strContent+strLabels).length() <= 0 ){
        		if (mLongestEverContent.length() <= 0 ){
        			saveAsSelfToDB(strTitle, strContent, strLabels);
        			tracker.trackEvent(
            	            "AuBlogLifeCycleEvent",  // Category
            	            "Save",  // Action
            	            "save as self:no new text: "+mAuBlogInstallId, // Label
            	            311);       // Value
        			return;
        		}
        		//if the user blanked out the blog entry, probably they are restarting from scratch so set the parent to zero node
        		daughterValues.put(AuBlogHistory.PARENT_ENTRY, AuBlogHistoryDatabase.ROOT_ID_DEFAULT);
        		
    		}else{
    			daughterValues.put(AuBlogHistory.PARENT_ENTRY, mUri.getLastPathSegment());
    		}
    		Uri daughterUri = getContentResolver().insert(AuBlogHistory.CONTENT_URI, daughterValues);
    		tracker.trackEvent(
    	            "AuBlogLifeCycleEvent",  // Category
    	            "Save",  // Action
    	            "save as daughter: "+mAuBlogInstallId, // Label
    	            312);       // Value
    		/*
    		 * Save parent but just tell it has a daughter, dont put the new values into its entry.
    		 * It should stay the way it was last saved when the user pushed the save button.
    		 */
//    		ContentValues parentValues = new ContentValues();
//    		parentValues.put(AuBlogHistory.DELETED,"true");
//    		getContentResolver().update(mUri, parentValues,null, null);
    		/*
    		 * Set the daughter to the active mUri, and reinitialize the state values to the daughers values
    		 */
    		mPostParent=mUri.getLastPathSegment();
    		//Toast.makeText(EditBlogEntryActivity.this, "Post "+daughterUri.getLastPathSegment()+" saved as daugher of: " +mUri.getLastPathSegment()+" to database\n\nTitle: "+mPostTitle+"\nLabels: "+mPostLabels+"\n\nPost: "+mPostContent, Toast.LENGTH_LONG).show();
    		mUri=daughterUri;
    		getIntent().setData(mUri);
    		saveAsSelfToDB(strTitle, strContent, strLabels);
    		
    		/*
    		 * If this save to database includes a new audio file, send it for transcription with this 
    		 * daughter uri to edit when it comes back to the edit activity with transcription content.
    		 */
    		if(mSendForTranscription ==true){
    			Intent intent = new Intent(this, NotifyingTranscriptionIntentService.class);
	            intent.putExtra(NotifyingTranscriptionService.EXTRA_AUDIOFILE_FULL_PATH, mAudioResultsFile);
	            intent.putExtra(NotifyingTranscriptionService.EXTRA_SPLIT_TYPE, NotifyingTranscriptionService.SPLIT_ON_SILENCE);
	            intent.putExtra(NotifyingTranscriptionIntentService.EXTRA_CORRESPONDING_DRAFT_URI_STRING, mUri.toString());
	            startService(intent); 
	            mSendForTranscription = false;
	            mAudioResultsFileStatus="recordingsenttotranscriptionservice";
            }
    		mDeleted=false;
    		mPostId=mUri.getLastPathSegment();
    		
    	} catch (SQLException e) {
    		tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Database connection problem "+e+" : "+mAuBlogInstallId, // Label
    	            3101);       // Value
    		// Log.e(TAG,"SQLException (createPost(title, content))");
    		Toast.makeText(EditBlogEntryActivity.this, "Database connection problem "+e, Toast.LENGTH_LONG).show();
    	} catch (Exception e) {
    		// Log.e(TAG, "Exception: " + e.getMessage());
    		
    		//Toast.makeText(EditBlogEntryActivity.this, "Exception "+e, Toast.LENGTH_LONG).show();
    		tracker.trackEvent(
    	            "Database",  // Category
    	            "Bug",  // Action
    	            "Unknown exception "+e+" : "+mAuBlogInstallId, // Label
    	            3102);       // Value
    	}
    	flagDraftTreeAsNeedingToBeReGenerated();

	}
	private void flagDraftTreeAsNeedingToBeReGenerated(){
		/*
    	 * Flag the draft tree as needing to be regenerated
    	 */
    	SharedPreferences prefs = getSharedPreferences(PreferenceConstants.PREFERENCE_NAME, MODE_PRIVATE);
    	SharedPreferences.Editor editor = prefs.edit();
    	editor.putBoolean(PreferenceConstants.PREFERENCE_DRAFT_TREE_IS_FRESH,false);
    	editor.commit();
	}
	public boolean onKeyDown(int keyCode, KeyEvent event) {
		if (keyCode == KeyEvent.KEYCODE_BACK) {
//			mWebView.loadUrl("javascript:savePostToDB()");
		}
//		if (keyCode == KeyEvent.KEYCODE_MENU) {
//			int tmp1 = 0, tmp2 = 0;
//			tmp1 = postContent.getSelectionStart();
//			tmp2 = postContent.getSelectionEnd();
//			selectionStart = Math.min(tmp1, tmp2);
//			selectionEnd = Math.max(tmp1, tmp2);
//		}
		return super.onKeyDown(keyCode, event);
	}
    
	
    /**
     * Provides a hook for calling "alert" from javascript. Useful for
     * debugging your javascript.
     */
    final class MyWebChromeClient extends WebChromeClient {
        @Override
        public boolean onJsAlert(WebView view, String url, String message, JsResult result) {
            Log.d(TAG, message);
            result.confirm();
            return true;
        }
        
    }

    @Override
	public boolean onCreateOptionsMenu(Menu menu) {
		// Hold on to this
		mMenu = menu;
		// Inflate the currently selected menu XML resource.
		MenuInflater inflater = getMenuInflater();
		inflater.inflate(R.menu.drafts_tree_menu, menu);
		return true;
	}
	@Override
	public boolean onOptionsItemSelected(MenuItem item) {
		switch (item.getItemId()) {
		// For "Title only": Examples of matching an ID with one assigned in
		//                   the XML
		case R.id.open_settings:
			tracker.trackPageView("/settingsScreen");
			tracker.trackEvent(
		            "Clicks",  // Category
		            "Button",  // Action
		            "clicked settings in the edit blog entry menu: "+mAuBlogInstallId, // Label
		            34);       // Value
			Intent i = new Intent(getBaseContext(),	SetPreferencesActivity.class);
			startActivity(i);
			return true;
		case R.id.new_entry:
			tracker.trackPageView("/editBlogEntryScreen");
			tracker.trackEvent(
		            "Clicks",  // Category
		            "Button",  // Action
		            "clicked new entry in the edit blog entry menu: "+mAuBlogInstallId, // Label
		            32);       // Value

			Intent intent = new Intent(getBaseContext(), EditBlogEntryActivity.class);

			Uri uri = getContentResolver().insert(AuBlogHistory.CONTENT_URI,
					null);
			// If we were unable to create a new blog entry, then just finish
			// this activity. A RESULT_CANCELED will be sent back to the
			// original activity if they requested a result.
			if (uri == null) {
				Log.e(TAG, "Failed to insert new blog entry into "
						+ getIntent().getData());
				Toast.makeText(
						EditBlogEntryActivity.this,
						"Failed to insert new blog entry into the database. You can go to your devices settings, choose Aublog and click Clear data to re-create the database."
								+ getIntent().getData() + " with this uri"
								+ AuBlogHistory.CONTENT_URI, Toast.LENGTH_LONG)
						.show();
				tracker.trackEvent(
			            "Database",  // Category
			            "Bug",  // Action
			            "cannot create new entry in the edit blog entry menu: "+mAuBlogInstallId, // Label
			            30);       // Value

			} else {
				intent.setData(uri);
				startActivity(intent);
				finish();
			}
			return true;
		default:
			// Do nothing

			break;
		}
		return false;
	}
}